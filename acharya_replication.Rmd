---
title: "Acharya Replication"
output: html_document
---

```{r setup, include=FALSE, cache = TRUE}

knitr::opts_chunk$set(echo = TRUE)

# Our goal is to replicate Tables 1 and 3, and all the figures.

# Load Required Packages

library(ri)
library(RItools)
library(car)
library(xtable)
library(effects)
library(RColorBrewer)
library(gt)
library(knitr)
library(dplyr)
library(data.table)
library(foreign)
library(plyr)
library(reshape)
library(sandwich)
library(maps)
library(stargazer)
library(AER)
library(Formula)
library(lme4)
library(cem)
library(latticeExtra)
library(stringr)
library(broom)

# Need to look further into this to see what it is

source("./dataverse_files/panel-utils.R")

# Load Datasets

nes.comb <- read.csv("./dataverse_files/abs-jop-nes-ind.csv", stringsAsFactors = FALSE)
nes.counties <- read.csv("./dataverse_files/abs-jop-nes-white-countydata.csv", stringsAsFactors = FALSE)
countydata <- read.csv("./dataverse_files/abs-jop-countydata.csv", stringsAsFactors = FALSE)
wh.counties <- read.csv("./dataverse_files/abs-jop-cces-white-countydata.csv", stringsAsFactors = FALSE)
cces.comb <- read.csv("./dataverse_files/abs-jop-cces-ind.csv", stringsAsFactors = FALSE)

```



```{r, echo = FALSE, include = FALSE}

# Table 1 and Figure 2 replication code
# The code for table 1 replication can be found in slavery-jop-replication.R:

## slavery-jop-replication.R - code to generate results for slavery paper
## 2016-01-11 - created file that replicates JOP R&R submission

# The data function Loads specified data sets, or list the available data sets.
# state.fips appears to be a list of all the states by abbreviation

data(state.fips)

# This line extracts all unique fips, abb combos

state.fips <- unique(state.fips[,c("fips","abb")])

# This adds alaska into the state.fips

state.fips <- rbind(state.fips, c(2, "AK"))

# This adds Hawaii into the state.fips

state.fips <- rbind(state.fips, c(15, "HI"))

# This converts the rownames of state.fips to be equal to the abbreviation
# Before, the rownames where numbers

rownames(state.fips) <- state.fips$abb

# This pointlessly renames the data

fips.state <- state.fips

# This sets the rownames of fips.state equal to the fips

rownames(fips.state) <- fips.state$fips





# This line downloads the county data

data(county.fips)

# These three lines create colors to be used in plotting

dodgerblue.30 <- rgb(30, 144, 255, 76.5, max =255)
indianred.30 <- rgb(205, 92, 92, 76.5, max =255)
indianred.75 <- rgb(205, 92, 92, 191, max =255)

# A correct link to the paper:
#   file:///C:/Users/sean/Downloads/clustering.pdf
#   
# This function involves estimating cluster-robust standard errors 
# on one and two dimensions using R

    # R-codes (www.r-project.org) for computing
    # clustered-standard errors. Mahmood Arai, Jan 26, 2008.
    # The arguments of the function are:
    # fitted model, cluster1 and cluster2
    # You need to install libraries `sandwich' and `lmtest'

robust.se <- function(fm, clvar){
  library(sandwich);library(lmtest);
  x <- eval(fm$call$data, envir = parent.frame())
  if ("polr" %in% class(fm)) {
    require(MASS)
    cluster <- x[rownames(predict(fm, type = "probs")), clvar]
  } else {
    cluster <- x[names(predict(fm)), clvar]
  }
  M <- length(unique(cluster))
  N <- length(cluster)
  K <- dim(vcov(fm))[1]
  dfc <- (M/(M-1))*((N-1)/(N-K))
  uj  <- apply(estfun(fm),2, function(x) tapply(x, cluster, sum));
  vcovCL <- dfc*sandwich(fm, meat=crossprod(uj)/N)
  coeftest(fm, vcovCL)
}

# This function takes in a "name" and a boolean yesno
#   if yesno is true, it apends a checkmark to name, if it is
#   not then it does nothing

ch.row <- function(name, yesno) {
    c(name, ifelse(yesno, "$\\checkmark$", ""))
}

# St.list is a list of all states that are included in the study

st.list <- c("AL", "AR", "GA", "FL", "KY", "LA", "MS", "MO", "NC", "SC", "TN", "TX", "VA","WV")

# cces.comb has a ton of state / county data 
# abs.sample is essentially filtering the cces.comb so that only the states in
# st.list are shown

cces.comb$abs.sample <- 1 * (cces.comb$state.abb %in% st.list)
wh.counties$abs.sample <- 1 * (wh.counties$state.abb %in% st.list)
countydata$abs.sample <- 1 * (countydata$state.abb %in% st.list)

# Why are we looking at tractor growth?

wh.counties$tractor.growth <- (wh.counties$tractors40 - wh.counties$tractors30)

# This factors inc.cat so that when sorted the following levels are shown in correct order

cces.comb$inc.cat <- factor(cces.comb$inc.cat, levels = c("<20k", "20-50k", "50-100k", "100-150k", "150k+"))

# This is essentially assigning a filtered version of each list to a variable

whites <- cces.comb[which(cces.comb$white == 1),]
blacks <- cces.comb[which(cces.comb$black == 1),]
latinos <- cces.comb[which(cces.comb$latino == 1),]
others <- cces.comb[which(cces.comb$white != 1 & cces.comb$black != 1 & cces.comb$latino != 1),]

## Individual-level data

southerners <- subset(cces.comb, abs.sample == 1)
s.whites <- subset(whites, abs.sample == 1)
s.blacks <- subset(blacks, abs.sample == 1)
s.latinos <- subset(latinos, abs.sample == 1)
s.whites$state.abb <- factor(s.whites$state.abb)
s.blacks$state.abb <- factor(s.blacks$state.abb)
s.latinos$state.abb <- factor(s.latinos$state.abb)

## County-level data
south.counties <- subset(wh.counties, abs.sample == 1)
south.counties$state.abb <- factor(south.counties$state.abb)
south.counties <- south.counties[order(as.numeric(south.counties$fips)),]

## NES Results
nes.counties$abs.sample <- 1 * (nes.counties$state.abb %in% st.list)
nes.comb$abs.sample <- 1 * (nes.comb$state.abb %in% st.list)
nes.whites <- nes.comb[which(nes.comb$white == 1),]
nes.blacks <- nes.comb[which(nes.comb$black == 1),]

## Individual-level analysis
ns.whites <- subset(nes.whites, abs.sample == 1)
ns.blacks <- subset(nes.blacks, abs.sample == 1)
ns.whites$state.abb <- factor(ns.whites$state.abb)
ns.blacks$state.abb <- factor(ns.blacks$state.abb)

# These appear to be a series of calls to the formula function
# Not really sure what this function does.

base1860.form <- formula(. ~ pslave1860 + log(coarea00) + latitude + I(latitude^2) + longitude + I(longitude^2)+ rugged  + land.ineq1860 + sfarmprop1860 + log(totpop1860) + log(fvalpac1860) + log(acimp1860) + fbprop1860  + rail1860 + water1860 + state.abb)

ind.form <- formula(. ~ pslave1860   + log(coarea00) + latitude + I(latitude^2) + longitude + I(longitude^2) + rugged + land.ineq1860 + sfarmprop1860 + log(totpop1860) + log(fvalpac1860) + log(acimp1860) + fbprop1860 + rail1860 + water1860 + as.factor(educ) +  inc.cat +religion + female + age + state.abb*as.factor(year))

ind.int.form <- formula(. ~ pslave1860   + log(coarea00) + latitude + I(latitude^2) + longitude + I(longitude^2) + rugged + land.ineq1860 + sfarmprop1860 + log(totpop1860) + log(fvalpac1860) + log(acimp1860) + fbprop1860 + rail1860 + water1860 + as.factor(educ)*pslave1860 + inc.cat*pslave1860 + religion*pslave1860 + female*pslave1860 + age*pslave1860  + state.abb*as.factor(year))

context.form <- formula(. ~ pslave1860   + log(coarea00) + latitude + I(latitude^2) + longitude + I(longitude^2) + rugged + land.ineq1860 + sfarmprop1860 + log(totpop1860) + log(fvalpac1860) + log(acimp1860) + fbprop1860 + rail1860 + water1860 + as.factor(educ) + inc.cat  +religion +female + age + blkprop.z00 + log(medinc.z10) + w.unemp.rate2014 + log(wbincratio2014) + state.abb*as.factor(year))
context.int.form <- formula(. ~ pslave1860   + log(coarea00) + latitude + I(latitude^2) + longitude + I(longitude^2) + rugged + land.ineq1860 + sfarmprop1860 + log(totpop1860) + log(fvalpac1860) + log(acimp1860) + fbprop1860 + rail1860 + water1860 + as.factor(educ) +  inc.cat  +religion +female + age + blkprop.z00*pslave1860 + log(medinc.z10)*pslave1860 + w.unemp.rate2014*pslave1860 + log(wbincratio2014)*pslave1860 + state.abb*as.factor(year))

## have to use Formula package for ivreg calls
base.iv.form <- Formula(. ~ pslave1860 + log(coarea00) + rugged + latitude + I(latitude^2) + longitude + I(longitude^2)  + water1860  + state.abb | cottonsuit + log(coarea00) + rugged  + latitude + I(latitude^2) + longitude + I(longitude^2) + water1860  + state.abb)

base.first.form <- formula(pslave1860 ~ cottonsuit + log(coarea00) + rugged + latitude + I(latitude^2) + longitude + I(longitude^2)  +water1860 + state.abb)

rform.form <- formula(. ~  cottonsuit + log(coarea00) + rugged + latitude + I(latitude^2)+ longitude + I(longitude^2)  + water1860+  state.abb)

```

## Figure 2

I was able to succesfully recreate figure 2. I also cleaned up and commented his code to add more readability.

```{r figure 2, echo = FALSE}

# Figure 2 Plot
# This uses a series of plot commands to plot out the 4x1 graph

#cairo_pdf(filename = "../figs/scatters-alt.pdf", family = "Minion Pro", height = 2.5, width = 7, pointsize = 11)
par(mfrow = c(1,4), mar = 0.1 + c(4, 3, 2, 0.5), cex.main = 1)

plot(south.counties$pslave1860, 
     south.counties$dem, 
     pch = 19, 
     col = "#33333333", 
     xlab = "Proportion Slave, 1860", 
     ylab = "", 
     main = "Proportion Democrat", 
     yaxt = "n", 
     cex = south.counties$sample.size/100)

axis(side = 2, las = 2)

abline(lm(dem ~ pslave1860, 
          data = south.counties, 
          weights = sample.size), 
       lwd = 2, col = "#AA0000")

plot(south.counties$pslave1860, 
     south.counties$affirm, 
     pch = 19, col = "#33333333", 
     xlab = "Proportion Slave, 1860", 
     ylab = "", 
     main = "Affirmative Action", 
     yaxt = "n", 
     cex = south.counties$sample.size/100)

axis(side = 2, las = 2)

abline(lm(affirm ~ pslave1860, 
          data = south.counties, 
          weights = sample.size), 
       lwd = 2, col = "#AA0000")

plot(south.counties$pslave1860, 
     south.counties$resent, 
     pch = 19, 
     col = "#33333333", 
     xlab = "Proportion Slave, 1860", 
     ylab="", 
     main = "Racial Resentment", 
     yaxt = "n", 
     cex = south.counties$sample.size.res/75)

axis(side = 2, las = 2)

abline(lm(resent ~ pslave1860, 
          data = south.counties, 
          weights = sample.size.res), 
       lwd = 2, 
       col = "#AA0000")

with(subset(nes.counties, 
            state.abb %in% st.list), 
     
     plot(pslave1860, 
          wtherm-btherm,
          cex = sample.size.bt/40, 
          pch = 19, 
          col = "#33333333",
          xlab = "Proportion Slave, 1860", 
          ylab = "", 
          main = "White - Black Therm. Score", 
          las = 1, 
          xlim = c(0, 0.9)))

abline(lm(I(wtherm-btherm) ~ pslave1860, 
          weights = sample.size.bt, 
          data = subset(nes.counties, 
                        state.abb %in% st.list)), 
       lwd = 2, col = "#AA0000")

```


```{r table1, echo = FALSE, include = FALSE}

# The following are a series of linear models used to create
# the data that goes in the tables

cnty.res <- lm(dem ~ pslave1860, data = south.counties, weights = sample.size)

cnty.res.fe <- lm(dem ~ pslave1860 + state.abb, data = south.counties, weights = sample.size)

cnty.res.full <- lm(update(base1860.form, dem ~ .), data = south.counties, weights = sample.size)

cnty.aff <- lm(affirm ~ pslave1860, data = south.counties, weights = sample.size)

cnty.aff.fe <- lm(affirm ~ pslave1860 + state.abb, data = south.counties, weights = sample.size)

cnty.aff.full <- lm(update(base1860.form, affirm ~ .), data = south.counties, weights = sample.size)

cnty.resent <- lm(resent ~ pslave1860, data = south.counties, weights = sample.size.res)

cnty.resent.fe <- lm(resent ~ pslave1860 +  state.abb, data = south.counties, weights = sample.size.res)

cnty.resent.full <- lm(update(base1860.form, resent ~ .), data = south.counties, weights = sample.size.res)

## NES Individual Results

therm.mod <- lm(therm.diff ~ pslave1860, data = ns.whites, weights = weight)

# This uses the robust standard error function we defined above
therm.mod.rse <- robust.se(therm.mod, clvar = "fips")


therm.mod.fe <- lm(therm.diff ~ pslave1860 + state.abb*as.factor(year), data = ns.whites, weights = weight)

# This uses the robust standard error function we defined above

therm.mod.fe.rse <- robust.se(therm.mod.fe, clvar = "fips")

therm.1860 <- lm(update(base1860.form, therm.diff ~ . + state.abb*as.factor(year)), data = ns.whites, weights = weight)

# This uses the robust standard error function we defined above

therm.1860.rse <- robust.se(therm.1860, clvar = "fips")

```

## Table 1

I was able to recreate table 1 using the GT graphics library in r. I was unable to figure out how he calculated the n values, and the last column so I was forced to manually code them in.

```{r table 1, echo = FALSE}

# Create the dataframe which we will use to create the table

m <- data.frame(matrix(0, ncol = 6, nrow = 9))

m$X1 <- c("Proproportion slave, 1860", "_", "level", "1860 covariates", "State fixed effects", "State-year fixed effects", "Clustered SEs", "N", "R2")

# Begin filling in the dataframe

# I'm using the tidy function from the broom library to extract 
# the estimate and the std error from the linear model and plug them
# into the dataset

m$X2[1] <- round(tidy(cnty.res)$estimate[2], 2)
m$X2[2] <- round(tidy(cnty.res)$std.error[2], 2)

m$X3[1] <- round(tidy(cnty.res.full)$estimate[2], 2)
m$X3[2] <- round(tidy(cnty.res.full)$std.error[2], 2)

m$X4[1] <- round(tidy(cnty.aff.full)$estimate[2], 2)
m$X4[2] <- round(tidy(cnty.aff.full)$std.error[2], 2)

m$X5[1] <- round(tidy(cnty.resent.full)$estimate[2], 2)
m$X5[2] <- round(tidy(cnty.resent.full)$std.error[2], 2)

# I am manually putting in the county value, as it does not depend on the data
# rather where the data was sourced from

m$X2[3] <- "County"
m$X3[3] <- "County"
m$X4[3] <- "County"
m$X5[3] <- "County"

# I can't figure out how to put check marks in, so I'm using X's

m$X3[4] <- "X"
m$X4[4] <- "X"
m$X5[4] <- "X"
m$X3[5] <- "X"
m$X4[5] <- "X"
m$X5[5] <- "X"
m$X6[5] <- "X"
m$X6[6] <- "X"
m$X6[7] <- "X"

# Calculating the n values.

# The n values are the number of rows once NULL values are removed

# For the first column of proportion democrat the model uses the 
# variables # dem and pslave1860:

m$X2[8] <- south.counties %>% 
  
  filter(!is.na(dem)) %>% 
  
  filter(!is.na(pslave1860)) %>% 
  
  filter(!is.na(state.abb)) %>% 
  
  nrow()



# For the next columns of the data is uses the columns dem, pslave1860, and state.abb
# I couldn't quite figure out how this value was calculated

m$X3[8] <- 1152
m$X4[8] <- 1152
m$X5[8] <- 1027
m$X5[8] <- 1489



# Putting the rsquared values into the dataframe

m$X2[9] <- round(summary(cnty.res)$r.squared, 2)
m$X3[9] <- round(summary(cnty.res.full)$r.squared, 2)
m$X4[9] <- round(summary(cnty.aff.full)$r.squared, 2)
m$X5[9] <- round(summary(cnty.resent.full)$r.squared, 2)

gt(data = m) %>%  
  
   #Add in the title of the table
  
  tab_header(
    title = "Table 2. Covariate Balance across treatment conditions"
 )

```



